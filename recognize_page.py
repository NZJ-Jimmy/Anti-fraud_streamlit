import streamlit as st
import pandas as pd
import plotly.express as px
from streamlit_extras.colored_header import colored_header
from streamlit_extras.stylable_container import stylable_container
from wordcloud import WordCloud
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import numpy as np
import time
import torch
import fraud_msg_cls
import jieba
from collections import Counter
import json

plt.rcParams["font.sans-serif"] = ["SimHei"]  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºä¸­æ–‡æ ‡ç­¾
plt.rcParams["axes.unicode_minus"] = False  # ç”¨æ¥æ­£å¸¸æ˜¾ç¤ºè´Ÿå·

with open("fraud_keywords.json", "r", encoding="utf-8") as f:
    keywords = json.load(f)
keywords = [keywords[i][0] for i in range(len(keywords))]

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# ---------------------------
# é¡µé¢é…ç½®
# ---------------------------
st.set_page_config(
    page_title="æ™ºèƒ½è¯ˆéª—ä¿¡æ¯æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸ›¡ï¸",
    layout="wide",
    initial_sidebar_state="expanded",
)

def extract_keywords(text, top_k=3):
    """æå–æ–‡æœ¬ä¸­çš„å±é™©å…³é”®è¯"""
    words = jieba.lcut(text)
    
    # è¿‡æ»¤æ¡ä»¶ï¼šé•¿åº¦ > 1 + éåœç”¨è¯ + å±äºå±é™©è¯è¡¨
    stopwords = {'çš„', 'äº†', 'æ˜¯', 'åœ¨', 'å’Œ', 'å°±', 'éƒ½', 'è€Œ', 'åŠ', 'ä¸', 'è¿™', 'é‚£', 'æœ‰'}
    danger_words = [
        word for word in words 
        if len(word) > 1 
        and word not in stopwords 
        and word in keywords
    ]
    
    # ç»Ÿè®¡è¯é¢‘å¹¶æ’åº
    word_counts = Counter(danger_words)
    
    # è·å–æ’åºåçš„å…³é”®è¯åˆ—è¡¨
    result = [word for word, _ in word_counts.most_common(top_k)]
    
    # å¦‚æœæ²¡æœ‰æ£€æµ‹åˆ°å…³é”®è¯ï¼Œè¿”å›åŒ…å«"æ— "çš„åˆ—è¡¨
    return result if result else ["æ— "]


def get_risk_level(res, prob):
    """æ ¹æ®æ¦‚ç‡è®¡ç®—é£é™©ç­‰çº§"""
    if res == "æ— é£é™©":
        return "æ— é£é™©"
    elif prob > 0.7:
        return "é«˜é£é™©"
    elif prob > 0.5:
        return "ä¸­é£é™©"
    else:
        return "ä½é£é™©"


def predict_text(text):
    try:
        predictions = fraud_msg_cls.predict(text)
        max_category, max_prob = predictions[0]

        # ç‰¹å¾è®¡ç®—å‡½æ•°
        def calculate_link_risk(text):
            """é“¾æ¥é£é™©è®¡ç®—ï¼šæ£€æŸ¥æ–‡æœ¬ä¸­çš„URL"""
            import re

            url_pattern = r"http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+|www\.[^\s]+"
            urls = re.findall(url_pattern, text)
            return min(len(urls) * 60 + 30, 100)  # æ¯ä¸ªé“¾æ¥å¢åŠ 30%é£é™©ï¼Œä¸Šé™100%

        def calculate_keyword_risk(text):
            """å…³é”®è¯é£é™©ï¼šåŸºäºé¢„å®šä¹‰è¯ˆéª—è¯è¡¨"""
            words = jieba.lcut(text)
            hit_count = sum(1 for word in words if word in keywords)
            return min(hit_count * 20 + 28, 100)  # æ¯ä¸ªå…³é”®è¯20%ï¼Œä¸Šé™100%

        def calculate_urgency_score(text):
            """ç´§è¿«æ€§è¯„åˆ†ï¼šæ£€æµ‹æ—¶é—´æ•æ„Ÿè¯æ±‡"""
            urgency_words = ["ç«‹å³", "é©¬ä¸Š", "å°½å¿«", "èµ¶å¿«", "ä»Šå¤©", "ç°åœ¨", "æœºä¼š"]
            words = jieba.lcut(text)
            count = sum(1 for word in words if word in urgency_words)
            return min(count * 25 + 32, 100)  # æ¯ä¸ªè¯25%ï¼Œä¸Šé™100%

        return {
            "prediction": max_category,
            "probability": float(max_prob),
            "features": {
                "é£é™©ç­‰çº§": get_risk_level(max_category, max_prob),
                "å…³é”®è¯": extract_keywords(text),
                # å®æ—¶ç‰¹å¾
                "å…³é”®è¯é£é™©": calculate_keyword_risk(text),
                "é“¾æ¥é£é™©": calculate_link_risk(text),
                "ç´§è¿«æ€§æŒ‡æ•°": calculate_urgency_score(text),
                "è¯­ä¹‰å¼‚å¸¸åº¦": max_prob * 100,  # ç›´æ¥ä½¿ç”¨æ¨¡å‹ç½®ä¿¡åº¦
            },
            "full_predictions": predictions,  # ä¿ç•™å®Œæ•´é¢„æµ‹ç»“æœ
        }
    except Exception as e:
        st.error(f"åˆ†æå¤±è´¥: {str(e)}")
        return None

# ---------------------------
# ä¾§è¾¹æ è¯´æ˜
# ---------------------------
with st.sidebar:
    st.header("ğŸ”– ä½¿ç”¨æŒ‡å—")
    with st.expander("ğŸ“Œ æ“ä½œè¯´æ˜"):
        st.markdown(
            """
        1. åœ¨æ–‡æœ¬æ¡†ä¸­è¾“å…¥å¾…æ£€æµ‹å†…å®¹
        2. ç‚¹å‡»ã€Œå¼€å§‹æ£€æµ‹ã€æŒ‰é’®
        3. æŸ¥çœ‹ä¸‹æ–¹åˆ†æç»“æœ
        4. ä½¿ç”¨ä¸‹æ–¹å·¥å…·è¿›è¡Œæ·±åº¦åˆ†æ
        """
        )

    with st.expander("âš™ï¸ é«˜çº§é€‰é¡¹"):
        confidence_threshold = st.slider(
            "ç½®ä¿¡åº¦é˜ˆå€¼", min_value=0.7, max_value=0.99, value=0.85, step=0.01
        )

        analysis_depth = st.selectbox("åˆ†ææ·±åº¦", ["å¿«é€Ÿæ¨¡å¼", "æ ‡å‡†æ¨¡å¼", "æ·±åº¦æ¨¡å¼"])
    
    with st.container(border=True):
        st.markdown("### â˜ï¸ åŠ¨æ€è¯äº‘")
        try:
            with open("wordcloud.html", "r", encoding="utf-8") as f:
                html_content = f.read()
            st.components.v1.html(html_content, height=300)
        except FileNotFoundError:
            st.warning("è¯äº‘æ–‡ä»¶æœªæ‰¾åˆ°")
        except Exception as e:
            st.error(f"è¯äº‘åŠ è½½å¤±è´¥: {str(e)}")


# ---------------------------
# è‡ªå®šä¹‰æ ·å¼
# ---------------------------
st.markdown(
    """
<style>
    /* ä¸»æ ‡é¢˜åŠ¨ç”» */
    @keyframes titleAnimation {
        0% { transform: translateY(-20px); opacity: 0; }
        100% { transform: translateY(0); opacity: 1; }
    }
    
    .main-title {
        animation: titleAnimation 1s ease-out;
        font-size: 2.8rem;
        text-align: center;
        background: linear-gradient(135deg, #ff6b6b, #ff8e8e);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        margin: 2rem 0;
    }
    
    /* è¾“å…¥æ¡†ç¾åŒ– */
    .stTextInput>div>div>input {
        border-radius: 15px;
        padding: 1.2rem;
        box-shadow: 0 2px 6px rgba(255,107,107,0.2);
    }
    
    /* åŠ¨æ€ç»“æœå¡ç‰‡ */
    .result-card {
        border-radius: 20px;
        padding: 2rem;
        margin: 1.5rem 0;
        box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        transition: all 0.3s ease;
    }
    
    /* è¯ˆéª—ç»“æœæ ·å¼ */
    .fraud-result {
        background: linear-gradient(135deg, #ff6b6b, #ff8e8e);
        color: white;
    }
    
    /* æ­£å¸¸ç»“æœæ ·å¼ */
    .normal-result {
        background: linear-gradient(135deg, #63cdda, #77ecb9);
        color: white;
    }
</style>
""",
    unsafe_allow_html=True,
)


# ---------------------------
# ç•Œé¢å¸ƒå±€
# ---------------------------
colored_header(
    label="æ™ºèƒ½è¯ˆéª—ä¿¡æ¯æ£€æµ‹",
    description="åŸºäº DeepSeek å¾®è°ƒçš„æ–‡æœ¬åˆ†ç±»å¼•æ“",
    color_name="gray-70",
)

# è¾“å…¥åŒºåŸŸ
with st.container(border=True):
    input_text = st.text_area(
        "ğŸ“ è¯·è¾“å…¥å¾…æ£€æµ‹çš„æ–‡æœ¬å†…å®¹ï¼š",
        height=100,
        placeholder="ä¾‹ï¼šã€é¡ºä¸°ã€‘å°Šæ•¬çš„å®¢æˆ·ï¼Œæ‚¨ä½¿ç”¨é¡ºä¸°çš„é¢‘ç‡è¾ƒé«˜ï¼Œç°èµ é€æ‚¨æš–é£æ‰‡ä¸€å°ï¼Œè¯·æ·»åŠ æ”¯ä»˜å®å¥½å‹è¿›è¡Œç™»è®°é¢†å–ã€‚",
        help="æ”¯æŒä¸­æ–‡æ–‡æœ¬æ£€æµ‹ï¼Œå»ºè®®è¾“å…¥50-500å­—",
    )

# åŠ¨æ€å¯è§†åŒ–ç»„ä»¶
col1, col2 = st.columns([5, 3])

# progress çŠ¶æ€ç²¾ç¡®æ§åˆ¶è¿›åº¦ç™¾åˆ†æ¯”
if "progress" not in st.session_state:
    st.session_state.progress = 0
if "new_result" not in st.session_state:
    st.session_state.new_result = False

with col1:
    # ä½¿ç”¨ç‹¬ç«‹å®¹å™¨æ§åˆ¶ç»“æœæ˜¾ç¤º
    result_container = st.empty()
    # æ£€æµ‹ç»“æœå±•ç¤º
    holder = st.empty()
    eval_bar = holder.progress(0.0, "**ğŸ˜´æœªå¼€å§‹æ£€æµ‹**")
    if st.button("å¼€å§‹æ£€æµ‹", use_container_width=True, type="primary"):
        if len(input_text) < 10:
            st.error("âš ï¸ è¾“å…¥æ–‡æœ¬è¿‡çŸ­ï¼Œè¯·è‡³å°‘è¾“å…¥10ä¸ªå­—ç¬¦")
        else:
            # é‡ç½®çŠ¶æ€
            st.session_state.new_result = False
            st.session_state.progress = 0

            eval_bar.progress(0.0, "**ğŸ¤¯åˆ†æä¸­...**")
            try:
                # è·å–å¹¶æ˜¾ç¤ºç»“æœ
                with st.spinner("â–¸â–¸ æ­£åœ¨ç”Ÿæˆå¯è§†åŒ–æŠ¥å‘Š..."):
                    result = predict_text(input_text)
                    st.session_state["detection_result"] = result
                    # ç«‹å³æ¸…é™¤æ—§ç»“æœ
                    result_container.empty()

                # æ¨¡æ‹Ÿè¿›åº¦æ¡ï¼ˆåæ‰§è¡Œï¼‰
                while st.session_state.progress < 100:
                    st.session_state.progress += 1
                    eval_bar.progress(st.session_state.progress, f"**ğŸ¤¯ æ·±åº¦åˆ†æä¸­... {st.session_state.progress}%**")
                    time.sleep(0.03)

                st.session_state["new_result"] = True
                # å®Œæˆæ—¶æ˜¾ç¤º
                eval_bar.progress(100, "**ğŸ«¡ åˆ†æå®Œæˆï¼**")
                time.sleep(0.5)
                st.toast(":rainbow[ç»“æœå·²å°±ç»ªï¼]", icon="ğŸ‰")

            finally:
                st.toast(":rainbow[è¯†åˆ«å®Œæˆï¼]", icon="ğŸ¥³")

    # æ£€æµ‹ç»“æœå±•ç¤ºï¼ˆç¡®ä¿å³ä½¿æ²¡ç‚¹æŒ‰é’®ï¼Œä»å¯æ˜¾ç¤ºä¹‹å‰çš„ç»“æœï¼‰
    if "detection_result" in st.session_state and st.session_state["new_result"]:
        result = st.session_state["detection_result"]
        risk_level = result['features']['é£é™©ç­‰çº§']
        keywords = result['features']['å…³é”®è¯']
        # é¢œè‰²æ˜ å°„é…ç½®
        color_map = {
            "æ— é£é™©": "#2ecc71",
            "ä½é£é™©": "#f1c40f",
            "ä¸­é£é™©": "#f39c12",
            "é«˜é£é™©": "#e74c3c"
        }
        # åŠ¨æ€ç”Ÿæˆæ˜¾ç¤ºå†…å®¹
        keywords_display = 'æ— ' if risk_level == "æ— é£é™©" else ', '.join(keywords) or 'æ— '
        with result_container.container():
            st.markdown(
                f"""
                <div style="padding:1rem; border-radius:15px; background:{color_map[risk_level]};">
                    <h2 style="color:white; text-align:center; margin:0;">ğŸ“Š ç»¼åˆé£é™©è¯„ä¼°</h2>
                    <h2 style="color:white; text-align:center; margin:1rem 0;">{risk_level}</h2>
                </div>
            """,
                unsafe_allow_html=True,
            )

            st.markdown(
                f"""
                ### ğŸ¯ æ£€æµ‹ç»“æœï¼š{result['prediction']}
                ### âš ï¸ å±é™©å…³é”®è¯ï¼š {keywords_display}
                """
            )


with col2:
    st.markdown("### ğŸ“Š å®æ—¶ç‰¹å¾åˆ†æ")
    with st.container(border=True):
        # åˆå§‹çŠ¶æ€/æœªæ£€æµ‹æ—¶çš„æç¤º
        if "detection_result" not in st.session_state or not st.session_state["new_result"]:
            st.info("ğŸ•’ ç­‰å¾…æ£€æµ‹æ•°æ®...")
        else:
            # åŠ¨æ€è·å–ç‰¹å¾æ•°æ®
            result = st.session_state["detection_result"]
            risk_level = result["features"]["é£é™©ç­‰çº§"]

            # æ ¹æ®é£é™©ç­‰çº§è°ƒæ•´è¯­ä¹‰æŒ‡æ ‡
            raw_semantic_value = result["features"]["è¯­ä¹‰å¼‚å¸¸åº¦"]  # è·å–åŸå§‹å€¼
            semantic_label = "å®‰å…¨ç½®ä¿¡åº¦" if risk_level == "æ— é£é™©" else "è¯­ä¹‰å¼‚å¸¸åº¦"

            features = {
                "å…³é”®è¯é£é™©": result["features"]["å…³é”®è¯é£é™©"],
                semantic_label: raw_semantic_value,  # åŠ¨æ€æ ‡ç­¾å
                "é“¾æ¥é£é™©": result["features"]["é“¾æ¥é£é™©"],
                "ç´§è¿«æ€§æŒ‡æ•°": result["features"]["ç´§è¿«æ€§æŒ‡æ•°"],
            }

            # é›·è¾¾å›¾æ•°æ®å‡†å¤‡
            categories = list(features.keys())
            values = list(features.values())

            # ä½¿é›·è¾¾å›¾é—­åˆ
            values += [values[0]]
            categories += [categories[0]]

            # åˆ›å»ºé›·è¾¾å›¾
            fig_radar = go.Figure()
            fig_radar.add_trace(
                go.Scatterpolar(
                    r=values,
                    theta=categories,
                    fill="toself",
                    marker=dict(size=8, color="#ff4b4b"),
                    line=dict(color="#ff4b4b", width=3),
                    name="ç‰¹å¾è¯„åˆ†",
                )
            )
            fig_radar.update_layout(
                polar=dict(
                    domain=dict(x=[0.1, 0.9], y=[0.1, 0.7]),
                    radialaxis=dict(range=[0, 100]),
                ),
                margin=dict(l=20, r=20, t=15, b=20),
                height=320
            )
            st.plotly_chart(fig_radar, use_container_width=True)

            # åˆ›å»ºä»ªè¡¨ç›˜
            fig_gauge = go.Figure(
                go.Indicator(
                    mode="gauge+number",
                    value=result["probability"] * 100,
                    number={"suffix": "%"},
                    domain={"x": [0, 1], "y": [0, 1]},
                    title={"text": "ç½®ä¿¡åº¦ä»ªè¡¨ç›˜"},
                    gauge={
                        "axis": {"range": [0, 100]},
                        "bar": {"color": "#ff6b6b"},
                        "steps": [
                            {"range": [0, 30], "color": "#63cdda"},
                            {"range": [30, 70], "color": "#ffeaa7"},
                            {"range": [70, 100], "color": "#ff6b6b"},
                        ],
                        "shape": "angular",
                    },
                )
            )
            fig_gauge.update_layout(
                height=200,
                margin=dict(t=50, b=8)
            )
            st.plotly_chart(fig_gauge, use_container_width=True)


# ---------------------------
# åº•éƒ¨ä¿¡æ¯
# ---------------------------
st.markdown("---")
footer = """
<div style="text-align: center; padding: 1rem; color: #666;">
    <div style="margin-bottom: 0.5rem;">
        ğŸ›¡ï¸ å®‰å…¨æç¤ºï¼šæœ¬ç³»ç»Ÿæ£€æµ‹ç»“æœä»…ä¾›å‚è€ƒï¼Œè¯·å‹¿ç›´æ¥ä½œä¸ºå¤„ç½®ä¾æ®
    </div>
</div>
"""
st.markdown(footer, unsafe_allow_html=True)
